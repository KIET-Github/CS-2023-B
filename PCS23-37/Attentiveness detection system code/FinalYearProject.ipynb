{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Numpy for array related functions\n",
    "import numpy as np\n",
    "# Dlib for deep learning based Modules and face landmark detection\n",
    "import dlib\n",
    "#face_utils for basic operations of conversion\n",
    "from imutils import face_utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\ihsud\\anaconda3\\lib\\site-packages (2.1.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from pygame import mixer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "sound = mixer.Sound('alarm.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain facial landmark from the image\n",
    "def get_landmarks(im):\n",
    "    rects = detector(im, 1)\n",
    "    if len(rects) > 1:\n",
    "        return \"error\"\n",
    "    if len(rects) == 0:\n",
    "        return \"error\"\n",
    "    return np.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function will return image with landmarks on the image\n",
    "def annotate_landmarks(im, landmarks):\n",
    "    im = im.copy()\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(im, str(idx), pos, fontFace= cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, fontScale=0.4, color=(0, 0, 255))\n",
    "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function will obtain the mean points of top lip\n",
    "def top_lip(landmarks):\n",
    "    top_lip_pts = []\n",
    "    for i in range(50,53):\n",
    "        top_lip_pts.append( landmarks[i])\n",
    "    for i in range(61,64):\n",
    "        top_lip_pts.append( landmarks[i])\n",
    "    top_lip_all_pts = np.squeeze( np.asarray( top_lip_pts))\n",
    "    top_lip_mean = np.mean(top_lip_pts, axis=0)\n",
    "    return int(top_lip_mean[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function will obtain the mean points of bottom lip\n",
    "def bottom_lip(landmarks):\n",
    "    bottom_lip_pts = []\n",
    "    for i in range(65,68):\n",
    "        bottom_lip_pts.append( landmarks[i])\n",
    "    for i in range(56,59):\n",
    "        bottom_lip_pts.append( landmarks[i])\n",
    "    bottom_lip_all_pts = np.squeeze(np.asarray( bottom_lip_pts))\n",
    "    bottom_lip_mean = np.mean(bottom_lip_pts, axis=0)\n",
    "    return int(bottom_lip_mean[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function will return distance between landmark image and two lips\n",
    "def mouth_open(image):\n",
    "    landmarks = get_landmarks(image)\n",
    "    if landmarks == \"error\":\n",
    "        return image, 0\n",
    "    face_frame = annotate_landmarks(image, landmarks)\n",
    "    top_lip_center = top_lip(landmarks)\n",
    "    bottom_lip_center = bottom_lip(landmarks)\n",
    "    lip_distance = abs(top_lip_center - bottom_lip_center)\n",
    "    return face_frame, lip_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "path = os.getcwd()\n",
    "drowsy = 0\n",
    "color=(0,0,0)\n",
    "status=\"\"\n",
    "score=0\n",
    "count=0\n",
    "thicc=0\n",
    "yawns = 0\n",
    "yawn_status = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(ptA,ptB):\n",
    "    dist = np.linalg.norm(ptA - ptB)\n",
    "    return dist\n",
    "\n",
    "def blinked(a,b,c,d,e,f):\n",
    "    up = compute(b,d) + compute(c,e)\n",
    "    down = compute(a,f)\n",
    "    ratio = up/(2.0*down)\n",
    "\n",
    "#Checking if it is blinked\n",
    "    if(ratio>0.25):\n",
    "        return 2\n",
    "    elif(ratio>0.21 and ratio<=0.25):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-b2d4d2013410>:4: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if landmarks == \"error\":\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-0611596a071e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# Obtain image_landmarks lip_distance from mouth_open function for current frame.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mface_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlip_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmouth_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;31m# Store current yawn_status in prev_yawn_status\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mprev_yawn_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myawn_status\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b2d4d2013410>\u001b[0m in \u001b[0;36mmouth_open\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This Function will return distance between landmark image and two lips\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmouth_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlandmarks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_landmarks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"error\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-f373459ff38f>\u001b[0m in \u001b[0;36mget_landmarks\u001b[1;34m(im)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_landmarks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrects\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"error\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrects\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "     # Read frames from webcam\n",
    "    _,frame = cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces= detector(gray)\n",
    "    #detected face in faces array\n",
    "    for face in faces:\n",
    "        x1 = face.left()\n",
    "        y1 = face.top()\n",
    "        x2 = face.right()\n",
    "        y2 = face.bottom()\n",
    "\n",
    "        face_frame=frame.copy()\n",
    "        \n",
    "        cv2.rectangle(face_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        landmarks = predictor(gray, face)\n",
    "        landmarks = face_utils.shape_to_np(landmarks)\n",
    "\n",
    "        #The numbers are actually the landmarks which will show eye\n",
    "        left_blink = blinked(landmarks[36],landmarks[37],landmarks[38], landmarks[41], landmarks[40], landmarks[39])\n",
    "        right_blink = blinked(landmarks[42],landmarks[43],landmarks[44], landmarks[47], landmarks[46], landmarks[45])\n",
    "        \n",
    "        #Now judge what to do for the eye blinks\n",
    "        if(left_blink==0 or right_blink==0):\n",
    "            score=score+1\n",
    "            drowsy=0\n",
    "            status=\"Sleeping\"\n",
    "\n",
    "        elif(left_blink==1 or right_blink==1):\n",
    "            sleep=0\n",
    "            active=0\n",
    "            drowsy+=1\n",
    "            if(drowsy>6):\n",
    "                status=\"Drowsy \"\n",
    "                color = (0,0,255)\n",
    "\n",
    "        else:\n",
    "            drowsy=0\n",
    "            score=score-1\n",
    "            status=\"Active\"\n",
    "        \n",
    "        cv2.putText(frame, status, (100,100), cv2.FONT_HERSHEY_SIMPLEX, 1, color,3)\n",
    "\n",
    "        for n in range(0, 68):\n",
    "            (x,y) = landmarks[n]\n",
    "            cv2.circle(face_frame, (x, y), 1, (255, 255, 255), -1)\n",
    "            \n",
    "    if(score<0):\n",
    "        score=0   \n",
    "    cv2.putText(frame,'Score:'+str(score), (100,40), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    if(score>30):\n",
    "        cv2.imwrite(os.path.join(path,'image.jpg'),frame)\n",
    "        try:\n",
    "            sound.play()\n",
    "        except:  # isplaying = False\n",
    "            pass\n",
    "        if(thicc<25):\n",
    "            thicc= thicc+2\n",
    "        else:\n",
    "            thicc=thicc-2\n",
    "            if(thicc<2):\n",
    "                thicc=2\n",
    "        cv2.rectangle(frame,(0,0),(100,100),(0,0,255),thicc)\n",
    "            \n",
    "    # Obtain image_landmarks lip_distance from mouth_open function for current frame.\n",
    "    face_frame, lip_distance = mouth_open(frame)\n",
    "    # Store current yawn_status in prev_yawn_status\n",
    "    prev_yawn_status = yawn_status\n",
    "    # If the lips distance is more than 25 then display subject is yawning along with yawn count.\n",
    "    if lip_distance > 30:\n",
    "        yawn_status = True\n",
    "        cv2.putText(frame, \"Yawning\", (250,250), cv2.FONT_HERSHEY_COMPLEX, 1,(0,0,255),2)\n",
    "        output_text = \" Yawn Count: \" + str(yawns + 1)\n",
    "        cv2.putText(frame, output_text, (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,127),2)\n",
    "    # If not lips distance is less than 25 then set yawn status to False\n",
    "    else:\n",
    "        yawn_status = False\n",
    "    # Increasing yawn count if subject was yawning in previous frame as well\n",
    "    if prev_yawn_status == True and yawn_status == False:\n",
    "        yawns += 1\n",
    "\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') and cv2.waitKey(1) == 13:\n",
    "        break\n",
    "     # Display live landmark of face\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Result of detector\", face_frame)\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
